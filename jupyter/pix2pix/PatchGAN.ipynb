{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import generic_utils\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Deconv2D, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import keras.backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/smiletranquilly/FYP/pix2pix'\n",
    "isExists=os.path.exists(root)\n",
    "if not isExists:\n",
    "    os.makedirs(root) \n",
    "os.chdir(root)\n",
    "\n",
    "dataFile = '/home/download/nyu_depth_v2_labeled.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X):\n",
    "    return X / 127.5 - 1\n",
    "\n",
    "\n",
    "def inverse_normalization(X):\n",
    "    return (X + 1.) / 2.\n",
    "\n",
    "\n",
    "def get_nb_patch(img_dim, patch_size, image_data_format):\n",
    "    assert image_data_format in [\"channels_first\", \"channels_last\"], \"Bad image_data_format\"\n",
    "    \n",
    "    if image_data_format == \"channels_first\":\n",
    "        assert img_dim[1] % patch_size[0] == 0, \"patch_size does not divide height\"\n",
    "        assert img_dim[2] % patch_size[1] == 0, \"patch_size does not divide width\"\n",
    "        nb_patch = (img_dim[1] // patch_size[0]) * (img_dim[2] // patch_size[1])\n",
    "        img_dim_disc = (img_dim[0], patch_size[0], patch_size[1])\n",
    "\n",
    "    elif image_data_format == \"channels_last\":\n",
    "        assert img_dim[0] % patch_size[0] == 0, \"patch_size does not divide height\"\n",
    "        assert img_dim[1] % patch_size[1] == 0, \"patch_size does not divide width\"\n",
    "        nb_patch = (img_dim[0] // patch_size[0]) * (img_dim[1] // patch_size[1])\n",
    "        img_dim_disc = (patch_size[0], patch_size[1], img_dim[-1])\n",
    "\n",
    "    return nb_patch, img_dim_disc\n",
    "\n",
    "\n",
    "def extract_patches(X, image_data_format, patch_size):\n",
    "\n",
    "    # Now extract patches form X_disc\n",
    "    if image_data_format == \"channels_first\":\n",
    "        X = X.transpose(0,2,3,1)\n",
    "\n",
    "    list_X = []\n",
    "    list_row_idx = [(i * patch_size[0], (i + 1) * patch_size[0]) for i in range(X.shape[1] // patch_size[0])]\n",
    "    list_col_idx = [(i * patch_size[1], (i + 1) * patch_size[1]) for i in range(X.shape[2] // patch_size[1])]\n",
    "\n",
    "    for row_idx in list_row_idx:\n",
    "        for col_idx in list_col_idx:\n",
    "            list_X.append(X[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])\n",
    "\n",
    "    if image_data_format == \"channels_first\":\n",
    "        for i in range(len(list_X)):\n",
    "            list_X[i] = list_X[i].transpose(0,3,1,2)\n",
    "\n",
    "    return list_X\n",
    "\n",
    "\n",
    "def load_data(dataFile, image_data_format):\n",
    "    \n",
    "    with h5py.File(dataFile, \"r\") as hf:\n",
    "\n",
    "        X_full_train = hf[\"images\"][:].astype(np.float32)\n",
    "        X_full_train = normalization(X_full_train)\n",
    "\n",
    "#         X_sketch_train = hf[\"train_data_sketch\"][:].astype(np.float32)\n",
    "#         X_sketch_train = normalization(X_sketch_train)\n",
    "\n",
    "        if image_data_format == \"channels_last\":\n",
    "            X_full_train = X_full_train.transpose(0, 2, 3, 1)\n",
    "#             X_sketch_train = X_sketch_train.transpose(0, 2, 3, 1)\n",
    "\n",
    "        X_full_val = hf[\"depths\"][:].astype(np.float32)\n",
    "        X_full_val = normalization(X_full_val)\n",
    "\n",
    "#         X_sketch_val = hf[\"val_data_sketch\"][:].astype(np.float32)\n",
    "#         X_sketch_val = normalization(X_sketch_val)\n",
    "\n",
    "        if image_data_format == \"channels_last\":\n",
    "            X_full_val = X_full_val.transpose(0, 2, 3, 1)\n",
    "#             X_sketch_val = X_sketch_val.transpose(0, 2, 3, 1)\n",
    "\n",
    "        return X_full_train,  X_full_val\n",
    "\n",
    "\n",
    "def gen_batch(X1, X2, batch_size):\n",
    "\n",
    "    while True:\n",
    "        idx = np.random.choice(X1.shape[0], batch_size, replace=False)\n",
    "        yield X1[idx], X2[idx]\n",
    "\n",
    "\n",
    "def get_disc_batch(X_full_batch, X_sketch_batch, generator_model, batch_counter, patch_size,\n",
    "                   image_data_format, label_smoothing=False, label_flipping=0):\n",
    "\n",
    "    # Create X_disc: alternatively only generated or real images\n",
    "    if batch_counter % 2 == 0:\n",
    "        # Produce an output\n",
    "        X_disc = generator_model.predict(X_sketch_batch)\n",
    "        y_disc = np.zeros((X_disc.shape[0], 2), dtype=np.uint8)\n",
    "        y_disc[:, 0] = 1\n",
    "\n",
    "        if label_flipping > 0:\n",
    "            p = np.random.binomial(1, label_flipping)\n",
    "            if p > 0:\n",
    "                y_disc[:, [0, 1]] = y_disc[:, [1, 0]]\n",
    "\n",
    "    else:\n",
    "        X_disc = X_full_batch\n",
    "        y_disc = np.zeros((X_disc.shape[0], 2), dtype=np.uint8)\n",
    "        if label_smoothing:\n",
    "            y_disc[:, 1] = np.random.uniform(low=0.9, high=1, size=y_disc.shape[0])\n",
    "        else:\n",
    "            y_disc[:, 1] = 1\n",
    "\n",
    "        if label_flipping > 0:\n",
    "            p = np.random.binomial(1, label_flipping)\n",
    "            if p > 0:\n",
    "                y_disc[:, [0, 1]] = y_disc[:, [1, 0]]\n",
    "\n",
    "    # Now extract patches form X_disc\n",
    "    X_disc = extract_patches(X_disc, image_data_format, patch_size)\n",
    "\n",
    "    return X_disc, y_disc\n",
    "\n",
    "\n",
    "def plot_generated_batch(X_full, X_sketch, generator_model, batch_size, image_data_format, suffix):\n",
    "\n",
    "    # Generate images\n",
    "    X_gen = generator_model.predict(X_sketch)\n",
    "\n",
    "    X_sketch = inverse_normalization(X_sketch)\n",
    "    X_full = inverse_normalization(X_full)\n",
    "    X_gen = inverse_normalization(X_gen)\n",
    "\n",
    "    Xs = X_sketch[:8]\n",
    "    Xg = X_gen[:8]\n",
    "    Xr = X_full[:8]\n",
    "\n",
    "    if image_data_format == \"channels_last\":\n",
    "        X = np.concatenate((Xs, Xg, Xr), axis=0)\n",
    "        list_rows = []\n",
    "        for i in range(int(X.shape[0] // 4)):\n",
    "            Xr = np.concatenate([X[k] for k in range(4 * i, 4 * (i + 1))], axis=1)\n",
    "            list_rows.append(Xr)\n",
    "\n",
    "        Xr = np.concatenate(list_rows, axis=0)\n",
    "\n",
    "    if image_data_format == \"channels_first\":\n",
    "        X = np.concatenate((Xs, Xg, Xr), axis=0)\n",
    "        list_rows = []\n",
    "        for i in range(int(X.shape[0] // 4)):\n",
    "            Xr = np.concatenate([X[k] for k in range(4 * i, 4 * (i + 1))], axis=2)\n",
    "            list_rows.append(Xr)\n",
    "\n",
    "        Xr = np.concatenate(list_rows, axis=1)\n",
    "        Xr = Xr.transpose(1,2,0)\n",
    "\n",
    "    if Xr.shape[-1] == 1:\n",
    "        plt.imshow(Xr[:, :, 0], cmap=\"gray\")\n",
    "    else:\n",
    "        plt.imshow(Xr)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"../../figures/current_batch_%s.png\" % suffix)\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minb_disc(x):\n",
    "    diffs = K.expand_dims(x, 3) - K.expand_dims(K.permute_dimensions(x, [1, 2, 0]), 0)\n",
    "    abs_diffs = K.sum(K.abs(diffs), 2)\n",
    "    x = K.sum(K.exp(-abs_diffs), 2)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def lambda_output(input_shape):\n",
    "    return input_shape[:2]\n",
    "\n",
    "\n",
    "\n",
    "def conv_block_unet(x, f, name, bn_mode, bn_axis, bn=True, strides=(2,2)):\n",
    "\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(f, (3, 3), strides=strides, name=name, padding=\"same\")(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def up_conv_block_unet(x, x2, f, name, bn_mode, bn_axis, bn=True, dropout=False):\n",
    "\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(f, (3, 3), name=name, padding=\"same\")(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "    if dropout:\n",
    "        x = Dropout(0.5)(x)\n",
    "    x = Concatenate(axis=bn_axis)([x, x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block_unet(x, x2, f, h, w, batch_size, name, bn_mode, bn_axis, bn=True, dropout=False):\n",
    "\n",
    "    o_shape = (batch_size, h * 2, w * 2, f)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Deconv2D(f, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "    if dropout:\n",
    "        x = Dropout(0.5)(x)\n",
    "    x = Concatenate(axis=bn_axis)([x, x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def generator_unet_upsampling(img_dim, bn_mode, model_name=\"generator_unet_upsampling\"):\n",
    "\n",
    "    nb_filters = 64\n",
    "\n",
    "    if K.image_dim_ordering() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "        nb_channels = img_dim[0]\n",
    "        min_s = min(img_dim[1:])\n",
    "    else:\n",
    "        bn_axis = -1\n",
    "        nb_channels = img_dim[-1]\n",
    "        min_s = min(img_dim[:-1])\n",
    "\n",
    "    unet_input = Input(shape=img_dim, name=\"unet_input\")\n",
    "\n",
    "    # Prepare encoder filters\n",
    "    nb_conv = int(np.floor(np.log(min_s) / np.log(2)))\n",
    "    list_nb_filters = [nb_filters * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "\n",
    "    # Encoder\n",
    "    list_encoder = [Conv2D(list_nb_filters[0], (3, 3),\n",
    "                           strides=(2, 2), name=\"unet_conv2D_1\", padding=\"same\")(unet_input)]\n",
    "    for i, f in enumerate(list_nb_filters[1:]):\n",
    "        name = \"unet_conv2D_%s\" % (i + 2)\n",
    "        conv = conv_block_unet(list_encoder[-1], f, name, bn_mode, bn_axis)\n",
    "        list_encoder.append(conv)\n",
    "\n",
    "    # Prepare decoder filters\n",
    "    list_nb_filters = list_nb_filters[:-2][::-1]\n",
    "    if len(list_nb_filters) < nb_conv - 1:\n",
    "        list_nb_filters.append(nb_filters)\n",
    "\n",
    "    # Decoder\n",
    "    list_decoder = [up_conv_block_unet(list_encoder[-1], list_encoder[-2],\n",
    "                                       list_nb_filters[0], \"unet_upconv2D_1\", bn_mode, bn_axis, dropout=True)]\n",
    "    for i, f in enumerate(list_nb_filters[1:]):\n",
    "        name = \"unet_upconv2D_%s\" % (i + 2)\n",
    "        # Dropout only on first few layers\n",
    "        if i < 2:\n",
    "            d = True\n",
    "        else:\n",
    "            d = False\n",
    "        conv = up_conv_block_unet(list_decoder[-1], list_encoder[-(i + 3)], f, name, bn_mode, bn_axis, dropout=d)\n",
    "        list_decoder.append(conv)\n",
    "\n",
    "    x = Activation(\"relu\")(list_decoder[-1])\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(nb_channels, (3, 3), name=\"last_conv\", padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    generator_unet = Model(inputs=[unet_input], outputs=[x])\n",
    "\n",
    "    return generator_unet\n",
    "\n",
    "\n",
    "def generator_unet_deconv(img_dim, bn_mode, batch_size, model_name=\"generator_unet_deconv\"):\n",
    "\n",
    "    assert K.backend() == \"tensorflow\", \"Not implemented with theano backend\"\n",
    "\n",
    "    nb_filters = 64\n",
    "    bn_axis = -1\n",
    "    h, w, nb_channels = img_dim\n",
    "    min_s = min(img_dim[:-1])\n",
    "\n",
    "    unet_input = Input(shape=img_dim, name=\"unet_input\")\n",
    "\n",
    "    # Prepare encoder filters\n",
    "    nb_conv = int(np.floor(np.log(min_s) / np.log(2)))\n",
    "    list_nb_filters = [nb_filters * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "\n",
    "    # Encoder\n",
    "    list_encoder = [Conv2D(list_nb_filters[0], (3, 3),\n",
    "                           strides=(2, 2), name=\"unet_conv2D_1\", padding=\"same\")(unet_input)]\n",
    "    # update current \"image\" h and w\n",
    "    h, w = h / 2, w / 2\n",
    "    for i, f in enumerate(list_nb_filters[1:]):\n",
    "        name = \"unet_conv2D_%s\" % (i + 2)\n",
    "        conv = conv_block_unet(list_encoder[-1], f, name, bn_mode, bn_axis)\n",
    "        list_encoder.append(conv)\n",
    "        h, w = h / 2, w / 2\n",
    "\n",
    "    # Prepare decoder filters\n",
    "    list_nb_filters = list_nb_filters[:-1][::-1]\n",
    "    if len(list_nb_filters) < nb_conv - 1:\n",
    "        list_nb_filters.append(nb_filters)\n",
    "\n",
    "    # Decoder\n",
    "    list_decoder = [deconv_block_unet(list_encoder[-1], list_encoder[-2],\n",
    "                                      list_nb_filters[0], h, w, batch_size,\n",
    "                                      \"unet_upconv2D_1\", bn_mode, bn_axis, dropout=True)]\n",
    "    h, w = h * 2, w * 2\n",
    "    for i, f in enumerate(list_nb_filters[1:]):\n",
    "        name = \"unet_upconv2D_%s\" % (i + 2)\n",
    "        # Dropout only on first few layers\n",
    "        if i < 2:\n",
    "            d = True\n",
    "        else:\n",
    "            d = False\n",
    "        conv = deconv_block_unet(list_decoder[-1], list_encoder[-(i + 3)], f, h,\n",
    "                                 w, batch_size, name, bn_mode, bn_axis, dropout=d)\n",
    "        list_decoder.append(conv)\n",
    "        h, w = h * 2, w * 2\n",
    "\n",
    "    x = Activation(\"relu\")(list_decoder[-1])\n",
    "    o_shape = (batch_size,) + img_dim\n",
    "    x = Deconv2D(nb_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    generator_unet = Model(inputs=[unet_input], outputs=[x])\n",
    "\n",
    "    return generator_unet\n",
    "\n",
    "\n",
    "def DCGAN_discriminator(img_dim, nb_patch, bn_mode, model_name=\"DCGAN_discriminator\", use_mbd=True):\n",
    "    \"\"\"\n",
    "    Discriminator model of the DCGAN\n",
    "    args : img_dim (tuple of int) num_chan, height, width\n",
    "           pretr_weights_file (str) file holding pre trained weights\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    list_input = [Input(shape=img_dim, name=\"disc_input_%s\" % i) for i in range(nb_patch)]\n",
    "\n",
    "    if K.image_dim_ordering() == \"channels_first\":\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = -1\n",
    "\n",
    "    nb_filters = 64\n",
    "    nb_conv = int(np.floor(np.log(img_dim[1]) / np.log(2)))\n",
    "    list_filters = [nb_filters * min(8, (2 ** i)) for i in range(nb_conv)]\n",
    "\n",
    "    # First conv\n",
    "    x_input = Input(shape=img_dim, name=\"discriminator_input\")\n",
    "    x = Conv2D(list_filters[0], (3, 3), strides=(2, 2), name=\"disc_conv2d_1\", padding=\"same\")(x_input)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    # Next convs\n",
    "    for i, f in enumerate(list_filters[1:]):\n",
    "        name = \"disc_conv2d_%s\" % (i + 2)\n",
    "        x = Conv2D(f, (3, 3), strides=(2, 2), name=name, padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=bn_axis)(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "\t# 全连接\n",
    "    x_flat = Flatten()(x)\n",
    "    x = Dense(2, activation=\"softmax\", name=\"disc_dense\")(x_flat)\n",
    "\n",
    "    PatchGAN = Model(inputs=[x_input], outputs=[x, x_flat], name=\"PatchGAN\")\n",
    "    print(\"PatchGAN summary\")\n",
    "    PatchGAN.summary()\n",
    "\n",
    "    x = [PatchGAN(patch)[0] for patch in list_input]\n",
    "    x_mbd = [PatchGAN(patch)[1] for patch in list_input]\n",
    "\n",
    "    if len(x) > 1:\n",
    "        x = Concatenate(axis=bn_axis)(x)\n",
    "    else:\n",
    "        x = x[0]\n",
    "\n",
    "    if use_mbd:\n",
    "        if len(x_mbd) > 1:\n",
    "            x_mbd = Concatenate(axis=bn_axis)(x_mbd)\n",
    "        else:\n",
    "            x_mbd = x_mbd[0]\n",
    "\n",
    "        num_kernels = 100\n",
    "        dim_per_kernel = 5\n",
    "\n",
    "        M = Dense(num_kernels * dim_per_kernel, use_bias=False, activation=None)\n",
    "        MBD = Lambda(minb_disc, output_shape=lambda_output)\n",
    "\n",
    "        x_mbd = M(x_mbd)\n",
    "        x_mbd = Reshape((num_kernels, dim_per_kernel))(x_mbd)\n",
    "        x_mbd = MBD(x_mbd)\n",
    "        x = Concatenate(axis=bn_axis)([x, x_mbd])\n",
    "\n",
    "    x_out = Dense(2, activation=\"softmax\", name=\"disc_output\")(x)\n",
    "\n",
    "    discriminator_model = Model(inputs=list_input, outputs=[x_out], name=model_name)\n",
    "\n",
    "    return discriminator_model\n",
    "\n",
    "\n",
    "def DCGAN(generator, discriminator_model, img_dim, patch_size, image_dim_ordering):\n",
    "\n",
    "    gen_input = Input(shape=img_dim, name=\"DCGAN_input\")\n",
    "\n",
    "    generated_image = generator(gen_input)\n",
    "\n",
    "    if image_dim_ordering == \"channels_first\":\n",
    "        h, w = img_dim[1:]\n",
    "    else:\n",
    "        h, w = img_dim[:-1]\n",
    "    ph, pw = patch_size\n",
    "\n",
    "    list_row_idx = [(i * ph, (i + 1) * ph) for i in range(h // ph)]\n",
    "    list_col_idx = [(i * pw, (i + 1) * pw) for i in range(w // pw)]\n",
    "\n",
    "    list_gen_patch = []\n",
    "    for row_idx in list_row_idx:\n",
    "        for col_idx in list_col_idx:\n",
    "            if image_dim_ordering == \"channels_last\":\n",
    "                x_patch = Lambda(lambda z: z[:, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1], :])(generated_image)\n",
    "            else:\n",
    "                x_patch = Lambda(lambda z: z[:, :, row_idx[0]:row_idx[1], col_idx[0]:col_idx[1]])(generated_image)\n",
    "            list_gen_patch.append(x_patch)\n",
    "\n",
    "    DCGAN_output = discriminator_model(list_gen_patch)\n",
    "\n",
    "    DCGAN = Model(inputs=[gen_input],\n",
    "                  outputs=[generated_image, DCGAN_output],\n",
    "                  name=\"DCGAN\")\n",
    "\n",
    "    return DCGAN\n",
    "\n",
    "\n",
    "def load(model_name, img_dim, nb_patch, bn_mode, use_mbd, batch_size):\n",
    "\n",
    "    if model_name == \"generator_unet_upsampling\":\n",
    "        model = generator_unet_upsampling(img_dim, bn_mode, model_name=model_name)\n",
    "        model.summary()\n",
    "        from keras.utils import plot_model\n",
    "        plot_model(model, to_file=\"../../figures/%s.png\" % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"generator_unet_deconv\":\n",
    "        model = generator_unet_deconv(img_dim, bn_mode, batch_size, model_name=model_name)\n",
    "        model.summary()\n",
    "        from keras.utils import plot_model\n",
    "        plot_model(model, to_file=\"../../figures/%s.png\" % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model\n",
    "\n",
    "    if model_name == \"DCGAN_discriminator\":\n",
    "        model = DCGAN_discriminator(img_dim, nb_patch, bn_mode, model_name=model_name, use_mbd=use_mbd)\n",
    "        model.summary()\n",
    "        from keras.utils import plot_model\n",
    "        plot_model(model, to_file=\"../../figures/%s.png\" % model_name, show_shapes=True, show_layer_names=True)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "\n",
    "def train(**kwargs):\n",
    "    \"\"\"\n",
    "    Train model\n",
    "    Load the whole train data in memory for faster operations\n",
    "    args: **kwargs (dict) keyword arguments that specify the model hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Roll out the parameters\n",
    "    batch_size = kwargs[\"batch_size\"]\n",
    "    n_batch_per_epoch = kwargs[\"n_batch_per_epoch\"]\n",
    "    nb_epoch = kwargs[\"nb_epoch\"]\n",
    "    model_name = kwargs[\"model_name\"]\n",
    "    generator = kwargs[\"generator\"]\n",
    "    image_data_format = kwargs[\"image_data_format\"]\n",
    "    img_dim = kwargs[\"img_dim\"]\n",
    "    patch_size = kwargs[\"patch_size\"]\n",
    "    bn_mode = kwargs[\"bn_mode\"]\n",
    "    label_smoothing = kwargs[\"use_label_smoothing\"]\n",
    "    label_flipping = kwargs[\"label_flipping\"]\n",
    "    dset = kwargs[\"dset\"]\n",
    "    use_mbd = kwargs[\"use_mbd\"]\n",
    "\n",
    "    epoch_size = n_batch_per_epoch * batch_size\n",
    "\n",
    "    # Setup environment (logging directory etc)\n",
    "    general_utils.setup_logging(model_name)\n",
    "\n",
    "    # Load and rescale data\n",
    "    X_full_train, X_sketch_train, X_full_val, X_sketch_val = data_utils.load_data(dset, image_data_format)\n",
    "    img_dim = X_full_train.shape[-3:]\n",
    "\n",
    "    # Get the number of non overlapping patch and the size of input image to the discriminator\n",
    "    nb_patch, img_dim_disc = data_utils.get_nb_patch(img_dim, patch_size, image_data_format)\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Create optimizers\n",
    "        opt_dcgan = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        # opt_discriminator = SGD(lr=1E-3, momentum=0.9, nesterov=True)\n",
    "        opt_discriminator = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "        # Load generator model\n",
    "        generator_model = models.load(\"generator_unet_%s\" % generator,\n",
    "                                      img_dim,\n",
    "                                      nb_patch,\n",
    "                                      bn_mode,\n",
    "                                      use_mbd,\n",
    "                                      batch_size)\n",
    "        # Load discriminator model\n",
    "        discriminator_model = models.load(\"DCGAN_discriminator\",\n",
    "                                          img_dim_disc,\n",
    "                                          nb_patch,\n",
    "                                          bn_mode,\n",
    "                                          use_mbd,\n",
    "                                          batch_size)\n",
    "\n",
    "        generator_model.compile(loss='mae', optimizer=opt_discriminator)\n",
    "        discriminator_model.trainable = False\n",
    "\n",
    "        DCGAN_model = models.DCGAN(generator_model,\n",
    "                                   discriminator_model,\n",
    "                                   img_dim,\n",
    "                                   patch_size,\n",
    "                                   image_data_format)\n",
    "\n",
    "        loss = [l1_loss, 'binary_crossentropy']\n",
    "        loss_weights = [1E1, 1]\n",
    "        DCGAN_model.compile(loss=loss, loss_weights=loss_weights, optimizer=opt_dcgan)\n",
    "\n",
    "        discriminator_model.trainable = True\n",
    "        discriminator_model.compile(loss='binary_crossentropy', optimizer=opt_discriminator)\n",
    "\n",
    "        gen_loss = 100\n",
    "        disc_loss = 100\n",
    "\n",
    "        # Start training\n",
    "        print(\"Start training\")\n",
    "        for e in range(nb_epoch):\n",
    "            # Initialize progbar and batch counter\n",
    "            progbar = generic_utils.Progbar(epoch_size)\n",
    "            batch_counter = 1\n",
    "            start = time.time()\n",
    "\n",
    "            for X_full_batch, X_sketch_batch in data_utils.gen_batch(X_full_train, X_sketch_train, batch_size):\n",
    "\n",
    "                # Create a batch to feed the discriminator model\n",
    "                X_disc, y_disc = data_utils.get_disc_batch(X_full_batch,\n",
    "                                                           X_sketch_batch,\n",
    "                                                           generator_model,\n",
    "                                                           batch_counter,\n",
    "                                                           patch_size,\n",
    "                                                           image_data_format,\n",
    "                                                           label_smoothing=label_smoothing,\n",
    "                                                           label_flipping=label_flipping)\n",
    "\n",
    "                # Update the discriminator\n",
    "                disc_loss = discriminator_model.train_on_batch(X_disc, y_disc)\n",
    "\n",
    "                # Create a batch to feed the generator model\n",
    "                X_gen_target, X_gen = next(data_utils.gen_batch(X_full_train, X_sketch_train, batch_size))\n",
    "                y_gen = np.zeros((X_gen.shape[0], 2), dtype=np.uint8)\n",
    "                y_gen[:, 1] = 1\n",
    "\n",
    "                # Freeze the discriminator\n",
    "                discriminator_model.trainable = False\n",
    "                gen_loss = DCGAN_model.train_on_batch(X_gen, [X_gen_target, y_gen])\n",
    "                # Unfreeze the discriminator\n",
    "                discriminator_model.trainable = True\n",
    "\n",
    "                batch_counter += 1\n",
    "                progbar.add(batch_size, values=[(\"D logloss\", disc_loss),\n",
    "                                                (\"G tot\", gen_loss[0]),\n",
    "                                                (\"G L1\", gen_loss[1]),\n",
    "                                                (\"G logloss\", gen_loss[2])])\n",
    "\n",
    "                # Save images for visualization\n",
    "                if batch_counter % (n_batch_per_epoch / 2) == 0:\n",
    "                    # Get new images from validation\n",
    "                    data_utils.plot_generated_batch(X_full_batch, X_sketch_batch, generator_model,\n",
    "                                                    batch_size, image_data_format, \"training\")\n",
    "                    X_full_batch, X_sketch_batch = next(data_utils.gen_batch(X_full_val, X_sketch_val, batch_size))\n",
    "                    data_utils.plot_generated_batch(X_full_batch, X_sketch_batch, generator_model,\n",
    "                                                    batch_size, image_data_format, \"validation\")\n",
    "\n",
    "                if batch_counter >= n_batch_per_epoch:\n",
    "                    break\n",
    "\n",
    "            print(\"\")\n",
    "            print('Epoch %s/%s, Time: %s' % (e + 1, nb_epoch, time.time() - start))\n",
    "\n",
    "            if e % 5 == 0:\n",
    "                gen_weights_path = os.path.join('../../models/%s/gen_weights_epoch%s.h5' % (model_name, e))\n",
    "                generator_model.save_weights(gen_weights_path, overwrite=True)\n",
    "\n",
    "                disc_weights_path = os.path.join('../../models/%s/disc_weights_epoch%s.h5' % (model_name, e))\n",
    "                discriminator_model.save_weights(disc_weights_path, overwrite=True)\n",
    "\n",
    "                DCGAN_weights_path = os.path.join('../../models/%s/DCGAN_weights_epoch%s.h5' % (model_name, e))\n",
    "                DCGAN_model.save_weights(DCGAN_weights_path, overwrite=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root = '/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model'\n",
    "os.chdir(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/models.py:56: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(512, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconv2D(f, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
      "/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/models.py:56: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(256, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconv2D(f, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
      "/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/models.py:56: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(128, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconv2D(f, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
      "/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/models.py:56: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(64, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconv2D(f, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n",
      "/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/models.py:171: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(1, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconv2D(nb_channels, (3, 3), output_shape=o_shape, strides=(2, 2), padding=\"same\")(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "unet_input (InputLayer)          (None, 256, 256, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_1 (Conv2D)           (None, 128, 128, 64)  640         unet_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)        (None, 128, 128, 64)  0           unet_conv2D_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_2 (Conv2D)           (None, 64, 64, 128)   73856       leaky_re_lu_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 64, 64, 128)   512         unet_conv2D_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)        (None, 64, 64, 128)   0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_3 (Conv2D)           (None, 32, 32, 256)   295168      leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 32, 32, 256)   1024        unet_conv2D_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)        (None, 32, 32, 256)   0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_4 (Conv2D)           (None, 16, 16, 512)   1180160     leaky_re_lu_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 16, 16, 512)   2048        unet_conv2D_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)        (None, 16, 16, 512)   0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_5 (Conv2D)           (None, 8, 8, 512)     2359808     leaky_re_lu_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 8, 8, 512)     2048        unet_conv2D_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, 8, 8, 512)     0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_6 (Conv2D)           (None, 4, 4, 512)     2359808     leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 4, 4, 512)     2048        unet_conv2D_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, 4, 4, 512)     0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_7 (Conv2D)           (None, 2, 2, 512)     2359808     leaky_re_lu_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 2, 2, 512)     2048        unet_conv2D_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, 2, 2, 512)     0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "unet_conv2D_8 (Conv2D)           (None, 1, 1, 512)     2359808     leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 1, 1, 512)     2048        unet_conv2D_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1, 1, 512)     0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, 2, 2, 512)     2359808     activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 2, 2, 512)     2048        conv2d_transpose_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2, 2, 512)     0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 2, 2, 1024)    0           dropout_1[0][0]                  \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2, 2, 1024)    0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, 4, 4, 512)     4719104     activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 4, 4, 512)     2048        conv2d_transpose_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 4, 512)     0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 4, 4, 1024)    0           dropout_2[0][0]                  \n",
      "                                                                   batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 4, 1024)    0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, 8, 8, 512)     4719104     activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 8, 8, 512)     2048        conv2d_transpose_3[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 8, 8, 512)     0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 8, 8, 1024)    0           dropout_3[0][0]                  \n",
      "                                                                   batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 8, 8, 1024)    0           concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, 16, 16, 512)   4719104     activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 16, 16, 512)   2048        conv2d_transpose_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 16, 16, 1024)  0           batch_normalization_11[0][0]     \n",
      "                                                                   batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 16, 16, 1024)  0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, 32, 32, 256)   2359552     activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 32, 32, 256)   1024        conv2d_transpose_5[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 32, 32, 512)   0           batch_normalization_12[0][0]     \n",
      "                                                                   batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32, 32, 512)   0           concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 64, 64, 128)   589952      activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 64, 64, 128)   512         conv2d_transpose_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 64, 64, 256)   0           batch_normalization_13[0][0]     \n",
      "                                                                   batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 64, 64, 256)   0           concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTransp (None, 128, 128, 64)  147520      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 128, 128, 64)  256         conv2d_transpose_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 128, 128, 128) 0           batch_normalization_14[0][0]     \n",
      "                                                                   unet_conv2D_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 128, 128, 128) 0           concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTransp (None, 256, 256, 1)   1153        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 256, 256, 1)   0           conv2d_transpose_8[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 30,626,113\n",
      "Trainable params: 30,615,233\n",
      "Non-trainable params: 10,880\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchGAN summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "disc_conv2d_1 (Conv2D)       (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "disc_conv2d_2 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "disc_dense (Dense)           (None, 2)                 262146    \n",
      "=================================================================\n",
      "Total params: 337,410\n",
      "Trainable params: 337,026\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "disc_input_0 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_1 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_2 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_3 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_4 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_5 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_6 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_7 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_8 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_9 (InputLayer)        (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_10 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_11 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_12 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_13 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_14 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "disc_input_15 (InputLayer)       (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "PatchGAN (Model)                 [(None, 2), (None, 13 337410      disc_input_0[0][0]               \n",
      "                                                                   disc_input_1[0][0]               \n",
      "                                                                   disc_input_2[0][0]               \n",
      "                                                                   disc_input_3[0][0]               \n",
      "                                                                   disc_input_4[0][0]               \n",
      "                                                                   disc_input_5[0][0]               \n",
      "                                                                   disc_input_6[0][0]               \n",
      "                                                                   disc_input_7[0][0]               \n",
      "                                                                   disc_input_8[0][0]               \n",
      "                                                                   disc_input_9[0][0]               \n",
      "                                                                   disc_input_10[0][0]              \n",
      "                                                                   disc_input_11[0][0]              \n",
      "                                                                   disc_input_12[0][0]              \n",
      "                                                                   disc_input_13[0][0]              \n",
      "                                                                   disc_input_14[0][0]              \n",
      "                                                                   disc_input_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 32)            0           PatchGAN[17][0]                  \n",
      "                                                                   PatchGAN[18][0]                  \n",
      "                                                                   PatchGAN[19][0]                  \n",
      "                                                                   PatchGAN[20][0]                  \n",
      "                                                                   PatchGAN[21][0]                  \n",
      "                                                                   PatchGAN[22][0]                  \n",
      "                                                                   PatchGAN[23][0]                  \n",
      "                                                                   PatchGAN[24][0]                  \n",
      "                                                                   PatchGAN[25][0]                  \n",
      "                                                                   PatchGAN[26][0]                  \n",
      "                                                                   PatchGAN[27][0]                  \n",
      "                                                                   PatchGAN[28][0]                  \n",
      "                                                                   PatchGAN[29][0]                  \n",
      "                                                                   PatchGAN[30][0]                  \n",
      "                                                                   PatchGAN[31][0]                  \n",
      "                                                                   PatchGAN[32][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "disc_output (Dense)              (None, 2)             66          concatenate_8[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 337,476\n",
      "Trainable params: 337,092\n",
      "Non-trainable params: 384\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected DCGAN_input to have shape (None, 256, 256, 1) but got array with shape (4, 256, 256, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Launch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mlaunch_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/main.py\u001b[0m in \u001b[0;36mlaunch_training\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Launch training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/FYP/HeightEstimation/IMG2DSM/model/train.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# Freeze the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_gen_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# Unfreeze the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mdiscriminator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected DCGAN_input to have shape (None, 256, 256, 1) but got array with shape (4, 256, 256, 3)"
     ]
    }
   ],
   "source": [
    "% run main.py 64 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
