{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 13] Permission denied: '/home/smiletranquilly/Multi-Scale_Deep_Network/coarse_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71f17788bca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misExists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# 如果不存在则创建目录\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'coarse_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0misExists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'fine_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/os.pyc\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[0;34m:\u001b[0m           \u001b[0;31m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 13] Permission denied: '/home/smiletranquilly/Multi-Scale_Deep_Network/coarse_data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "import hdf5storage\n",
    "import scipy.io as scio\n",
    "import h5py\n",
    "# %matplotlib inline\n",
    "from keras.models import Sequential, model_from_json, Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Reshape, concatenate, Activation, Flatten, merge\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, Dropout\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "#设置当前目录\n",
    "root = '/home/smiletranquilly/Multi-Scale_Deep_Network/' \n",
    "#os.chdir(root)\n",
    "\n",
    "coarse_dir=root+'/coarse_data/building_coarse_model.h5'\n",
    "coarse_weights=root+'/coarse_data/building_coarse_weights.h5'\n",
    "fine_dir=root+'/fine_data/building_fine_model.h5'\n",
    "fine_weights=root+'/fine_data/building_fine_weights.h5'\n",
    "\n",
    "log_corsepath = root+'/log/building_corse_log'\n",
    "log_finepath = root+'/log/building_fine_log'\n",
    "\n",
    "dataFile='/home/Dataset/Potsdam_1024.mat'\n",
    "\n",
    "# 新建文件夹\n",
    "isExists=os.path.exists(root+'coarse_data')    \n",
    "if not isExists:\n",
    "    # 如果不存在则创建目录\n",
    "    os.makedirs(root+'coarse_data')\n",
    "    \n",
    "isExists=os.path.exists(root+'fine_data')\n",
    "if not isExists:\n",
    "    os.makedirs(root+'fine_data')\n",
    "    \n",
    "isExists=os.path.exists(root+'log')\n",
    "if not isExists:\n",
    "    os.makedirs(root+'log')\n",
    "\n",
    "try:\n",
    "    os.makedirs(log_corsepath)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(log_finepath)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_invarient_error(y_true,y_pred):\n",
    "    log_1=K.log(K.clip(y_pred,K.epsilon(),np.inf)+1.)\n",
    "    log_2=K.log(K.clip(y_true,K.epsilon(),np.inf)+1.)\n",
    "    return K.mean(K.square(log_1-log_2),axis=-1)-Lambda*K.square(K.mean(log_1-log_2,axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pred_single_image_depth_using_fine(path):\n",
    "    model=load_model(fine_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    img_array=cv2.imread(path)\n",
    "    img_array=np.expand_dims(img_array,axis=0)\n",
    "    img_array=np.array([cv2.resize(img_array[i],(480,640)) for i in range(1)])\n",
    "    img_array=np.array([cv2.pyrDown(img_array[i]) for i in range(1)])\n",
    "    img_array=rescale(img_array)\n",
    "    out=model.predict(img_array)\n",
    "    return out\n",
    "\n",
    "def pred_single_image_depth_using_coarse(path):\n",
    "    model=load_model(coarse_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    img_array=cv2.imread(path)\n",
    "    img_array=np.expand_dims(img_array,axis=0)\n",
    "    img_array=np.array([cv2.resize(img_array[i],(480,640)) for i in range(1)])\n",
    "    img_array=np.array([cv2.pyrDown(img_array[i]) for i in range(1)])\n",
    "    img_array=rescale(img_array)\n",
    "    out=model.predict(img_array)\n",
    "    return out\n",
    "\n",
    "def pred_single_image_depth_using_coarse_array(image_array):\n",
    "    model=load_model(coarse_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    image_array=np.expand_dims(image_array,axis=0)\n",
    "    image_array=np.array([cv2.resize(image_array[i],(480,640)) for i in range(1)])\n",
    "    image_array=np.array([cv2.pyrDown(image_array[i]) for i in range(1)])\n",
    "    image_array=rescale(image_array)\n",
    "    out=model.predict(image_array)\n",
    "    return out\n",
    "\n",
    "def pred_single_image_depth_using_fine_array(image_array):\n",
    "    model=load_model(fine_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    image_array=np.expand_dims(image_array,axis=0)\n",
    "    image_array=np.array([cv2.resize(image_array[i],(480,640)) for i in range(1)])\n",
    "    image_array=np.array([cv2.pyrDown(image_array[i]) for i in range(1)])\n",
    "    image_array=rescale(image_array)\n",
    "    out=model.predict(image_array)\n",
    "    return out\n",
    "def display_image(path):\n",
    "    img_array=plt.imread(path)\n",
    "    img_array=np.expand_dims(img_array,axis=0) \n",
    "    img_array=np.array([cv2.resize(img_array[i],(480,640)) for i in range(1)])\n",
    "    img_array=rescale(img_array)\n",
    "    plt.imshow(img_array[0])\n",
    "    \n",
    "def eval(eval_dir):\n",
    "    #load_model\n",
    "    model=load_model(eval_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    print(model.evaluate(X_test,y_test))  \n",
    "    \n",
    "def rescale(data):\n",
    "    data=data.astype('float32')\n",
    "    data /= 255.0   \n",
    "    return data\n",
    "\n",
    "def rescale_float(label):\n",
    "    maxnum = np.max(label)\n",
    "    label=label.astype('float32')\n",
    "    label = label /255.0\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert(mat,start,end):\n",
    "# input must be matlab mat!\n",
    "    X=[]\n",
    "    y=[]\n",
    "    img = mat['images'] #image\n",
    "    depths = mat['depths'] # raw depths\n",
    "    for i in range(start, end): # include left not right!\n",
    "                img1 = img[i,...].transpose((1, 2, 0))\n",
    "                img2 = depths[i]     #np.transpose() \n",
    "                X.append(img1)\n",
    "                y.append(img2)\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def train_coarse():\n",
    "    inputs=Input(shape=(int(img_row/2),int(img_cols/2),3))\n",
    "\n",
    "    #coarse_1\n",
    "    coarse_1=Convolution2D(96,(11,11),strides=(4,4),padding='same')(inputs)\n",
    "    coarse_1=Activation('relu')(coarse_1)\n",
    "    coarse_1=MaxPooling2D(pool_size=(2, 2))(coarse_1)\n",
    "\n",
    "    #coarse_2\n",
    "    coarse_2=Convolution2D(256,(5,5),padding='same')(coarse_1)\n",
    "    coarse_2=Activation('relu')(coarse_2)\n",
    "    coarse_2=MaxPooling2D(pool_size=(2,2))(coarse_2)\n",
    "\n",
    "    #coarse_3\n",
    "    coarse_3=Convolution2D(384,(3,3),padding='same')(coarse_2)\n",
    "    coarse_3=Activation('relu')(coarse_3)\n",
    "\n",
    "    #coarse_4\n",
    "    coarse_4=Convolution2D(384,(3,3),padding='same')(coarse_3)\n",
    "    coarse_4=Activation('relu')(coarse_4)\n",
    "\n",
    "    #coarse_5\n",
    "    coarse_5=Convolution2D(256,(3,3),padding='same',)(coarse_4)\n",
    "    coarse_5=Activation('relu')(coarse_5)\n",
    "    coarse_5=MaxPooling2D(pool_size=(2,2))(coarse_5)\n",
    "\n",
    "    #coarse_6\n",
    "    coarse_6=Flatten(name='coarse_6')(coarse_5)\n",
    "    coarse_6=Dense(4096)(coarse_6)\n",
    "    coarse_6=Activation('relu')(coarse_6)\n",
    "    coarse_6=Dropout(0.5)(coarse_6)\n",
    "\n",
    "    # Coarse 7\n",
    "    coarse_7=Dense((int(img_row/8))*(int(img_cols/8)))(coarse_6)\n",
    "    coarse_7=Activation('linear')(coarse_7)\n",
    "    coarse_7=Reshape((int(img_row/8),int(img_cols/8)))(coarse_7)\n",
    "        \n",
    "    model=Model(input=inputs,output=coarse_7)\n",
    "    model.compile(loss=scale_invarient_error,optimizer=SGD(learning_rate,momentum),metrics=['accuracy'])\n",
    "    \n",
    "    #print model\n",
    "    model.summary() \n",
    "      \n",
    "    #将loss ，acc， val_loss ,val_acc记录tensorboard\n",
    "    tensorboard = TensorBoard(log_dir=log_corsepath)#, histogram_freq=1,write_graph=True,write_images=1\n",
    "                           \n",
    "    model.fit(X_train,y_train,epochs=coarse_epochs,batch_size=batch_size,shuffle=True,validation_split=0.2,callbacks=[tensorboard])\n",
    "                               \n",
    "    #save_model\n",
    "    model.save(coarse_dir)\n",
    " \n",
    "\n",
    "def train_fine():\n",
    "    #load_coarse_model:\n",
    "    model=load_model(coarse_dir,custom_objects={'scale_invarient_error':scale_invarient_error})\n",
    "    \n",
    "    for layers in model.layers:\n",
    "        layers.trainable=False\n",
    "    \n",
    "    #fine_model\n",
    "    inputs=model.input\n",
    "    \n",
    "    #fine_1:\n",
    "    fine_1=Convolution2D(63,(9,9),strides=(2,2),padding='same')(inputs)\n",
    "    fine_1=Activation('relu')(fine_1)\n",
    "    fine_1=MaxPooling2D(pool_size=(2,2))(fine_1)\n",
    "    \n",
    "    #fine_2:\n",
    "    coarse_output=model.output\n",
    "    coarse_output=Reshape((int(img_row/8),int(img_cols/8),1))(coarse_output)\n",
    "    fine_2=concatenate([fine_1,coarse_output],axis=3)\n",
    "    \n",
    "    #fine_3:\n",
    "    fine_3=Convolution2D(64,(5,5),padding='same')(fine_2)\n",
    "    fine_3=Activation('relu')(fine_3)\n",
    "    \n",
    "    #fine_4:\n",
    "    fine_4=Convolution2D(1,(5,5),padding='same')(fine_3)\n",
    "    fine_4=Activation('linear')(fine_4)\n",
    "    fine_4=Reshape((int(img_row/8),int(img_cols/8)))(fine_4)\n",
    "    \n",
    "    model=Model(input=inputs,output=fine_4)\n",
    "    model.compile(loss=scale_invarient_error,optimizer=SGD(learning_rate,momentum),metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    #将loss ，acc， val_loss ,val_acc记录tensorboard\n",
    "    tensorboard = TensorBoard(log_dir=log_finepath) #, histogram_freq=1,write_graph=True,write_images=1\n",
    "    history = model.fit(X_train,y_train,batch_size=batch_size,epochs=fine_epoches,shuffle=True,validation_split=0.2,callbacks=[tensorboard])\n",
    "    \n",
    "    #save model\n",
    "    model.save(fine_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "coarse_epochs = 1000\n",
    "fine_epoches = 1000\n",
    "img_row=1024\n",
    "img_cols=1024\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "Lambda=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950\n",
      "(760, 1024, 1024, 3)\n",
      "(760, 1024, 1024)\n",
      "(190, 1024, 1024, 3)\n",
      "(190, 1024, 1024)\n",
      "(760, 512, 512, 3)\n",
      "(760, 128, 128)\n",
      "(190, 512, 512, 3)\n",
      "(190, 128, 128)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 96)      34944     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 128, 96)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 64, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32, 32, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "coarse_6 (Flatten)           (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              268439552 \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16384)             67125248  \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 128, 128)          0         \n",
      "=================================================================\n",
      "Total params: 339,312,000\n",
      "Trainable params: 339,312,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:122: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"re..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 608 samples, validate on 152 samples\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "./log/building_corse_log; Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aae1762d0b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain_coarse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mtrain_fine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-49b3925a582b>\u001b[0m in \u001b[0;36mtrain_coarse\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_corsepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, histogram_freq=1,write_graph=True,write_images=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoarse_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m#save_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         callbacks.set_params({\n\u001b[1;32m   1157\u001b[0m             \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[0;32m--> 787\u001b[0;31m                                                 self.sess.graph)\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/tensorflow/python/summary/writer/writer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[0;32m--> 352\u001b[0;31m                                    filename_suffix)\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/tensorflow/python/summary/writer/event_file_writer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     self._ev_writer = pywrap_tensorflow.EventsWriter(\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.pyc\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    372\u001b[0m   \"\"\"\n\u001b[1;32m    373\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/smiletranquilly/.local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: ./log/building_corse_log; Permission denied"
     ]
    }
   ],
   "source": [
    "with h5py.File(dataFile, \"r\") as mat:\n",
    "    # number of the first dim\n",
    "    X_data = mat['images'][:].transpose((0,2, 3, 1))\n",
    "    y_data = mat['depths'][:]\n",
    "    image_num = len(X_data) \n",
    "    depth_num = len(y_data)\n",
    "    try:\n",
    "        image_num == depth_num\n",
    "    except IOError:\n",
    "        print \"number not match, input error!\"\n",
    "    print image_num\n",
    "\n",
    "#     X_1,y_1=convert(mat,0,image_num/4)\n",
    "#     X_2,y_2=convert(mat,image_num/4,image_num/2)\n",
    "#     X_3,y_3=convert(mat,image_num/2,3*image_num/4)\n",
    "#     X_4,y_4=convert(mat,3*image_num/4,image_num)\n",
    "\n",
    "#     print(X_1.shape,y_1.shape)\n",
    "#     print(X_2.shape,y_2.shape)\n",
    "#     print(X_3.shape,y_3.shape)\n",
    "#     print(X_4.shape,y_4.shape)\n",
    "#     X_5=np.concatenate((X_1,X_2),axis=0)\n",
    "#     # release memory\n",
    "#     del X_1,X_2\n",
    "#     y_5=np.concatenate((y_1,y_2),axis=0)\n",
    "#     del y_1,y_2\n",
    "\n",
    "#     X_6=np.concatenate((X_4,X_3),axis=0)\n",
    "#     del X_4,X_3\n",
    "#     y_6=np.concatenate((y_4,y_3),axis=0)    \n",
    "#     del y_4,y_3\n",
    "\n",
    "#     X_data = np.concatenate((X_5,X_6),axis=0)\n",
    "#     del X_5,X_6\n",
    "#     y_data = np.concatenate((y_5,y_6),axis=0)\n",
    "#     del y_5,y_6\n",
    "#     print(X_data.shape,y_data.shape)\n",
    "# 归一化\n",
    "X_data=rescale(X_data)\n",
    "y_data=rescale_float(y_data)\n",
    "\n",
    "train_end=int(0.8*image_num)\n",
    "test_num= image_num - train_end\n",
    "X_train=X_data[:train_end]\n",
    "y_train=y_data[:train_end]\n",
    "X_test=X_data[train_end:image_num]\n",
    "y_test=y_data[train_end:image_num]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "del X_data,y_data\n",
    "\n",
    "X_train=np.array([cv2.pyrDown(X_train[i]) for i in range(train_end)])\n",
    "y_train=np.array([cv2.pyrDown(y_train[i]) for i in range(train_end)])\n",
    "X_test=np.array([cv2.pyrDown(X_test[i]) for i in range(test_num)])\n",
    "y_test=np.array([cv2.pyrDown(y_test[i]) for i in range(test_num)])\n",
    "\n",
    "y_train=np.array([cv2.pyrDown(y_train[i]) for i in range(train_end)])\n",
    "y_test=np.array([cv2.pyrDown(y_test[i]) for i in range(test_num)])\n",
    "y_train=np.array([cv2.pyrDown(y_train[i]) for i in range(train_end)])\n",
    "y_test=np.array([cv2.pyrDown(y_test[i]) for i in range(test_num)])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "train_coarse()\n",
    "train_fine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(coarse_dir)\n",
    "eval(fine_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
